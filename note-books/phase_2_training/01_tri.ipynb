{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Notebook : Réunion des fichiers CSV en un fichier consolidé\n",
    "\n",
    "**Objectif :** Ce notebook a pour but de rassembler tous les fichiers CSV situés dans le dossier `note-books/phase_2_training/01_tri_CSV` en un seul fichier, sans faire de tri ni de nettoyage. Cela nous permettra de disposer d'un fichier de données unique pour faciliter les analyses futures.\n",
    "\n",
    "---\n",
    "\n",
    "## Étape 1 : Importer les bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explication :**  \n",
    "- `pandas` est utilisé pour manipuler les données, en particulier les fichiers CSV.\n",
    "- `os` nous aide à naviguer dans le système de fichiers et à créer des dossiers.\n",
    "\n",
    "---\n",
    "\n",
    "## Étape 2 : Lister tous les fichiers CSV dans le dossier cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers CSV trouvés dans le dossier :\n",
      "['chunk_35_filtered_part_0.csv', 'chunk_34_filtered_part_0.csv', 'chunk_33_filtered_part_0.csv', 'chunk_29_filtered_part_0.csv', 'chunk_30_filtered_part_0.csv', 'chunk_28_filtered_part_0.csv', 'chunk_31_filtered_part_0.csv', 'chunk_25_filtered_part_0.csv', 'chunk_24_filtered_part_0.csv', 'chunk_27_filtered_part_0.csv', 'chunk_26_filtered_part_0.csv', 'chunk_20_filtered_part_0.csv', 'chunk_21_filtered_part_0.csv', 'chunk_22_filtered_part_0.csv', 'chunk_23_filtered_part_0.csv', 'chunk_11_filtered_part_0.csv', 'chunk_16_filtered_part_0.csv', 'chunk_17_filtered_part_0.csv', 'chunk_14_filtered_part_0.csv', 'chunk_15_filtered_part_0.csv', 'chunk_19_filtered_part_0.csv']\n"
     ]
    }
   ],
   "source": [
    "# Spécifiez le dossier contenant les fichiers CSV\n",
    "folder_path = 'note-books/phase_2_training/01_tri_CSV'\n",
    "\n",
    "# Lister tous les fichiers CSV dans le dossier\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Afficher la liste des fichiers trouvés\n",
    "print(\"Fichiers CSV trouvés dans le dossier :\")\n",
    "print(csv_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explication :**  \n",
    "- `os.listdir(folder_path)` liste tous les fichiers dans le dossier, et nous filtrons pour ne garder que ceux qui se terminent par `.csv`.\n",
    "- Cela nous permet de vérifier que tous les fichiers CSV ont bien été trouvés.\n",
    "\n",
    "---\n",
    "## Étape 3 : Charger chaque fichier CSV et les ajouter à une liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_35_filtered_part_0.csv chargé avec succès.\n",
      "chunk_34_filtered_part_0.csv chargé avec succès.\n",
      "chunk_33_filtered_part_0.csv chargé avec succès.\n",
      "chunk_29_filtered_part_0.csv chargé avec succès.\n",
      "chunk_30_filtered_part_0.csv chargé avec succès.\n",
      "chunk_28_filtered_part_0.csv chargé avec succès.\n",
      "chunk_31_filtered_part_0.csv chargé avec succès.\n",
      "chunk_25_filtered_part_0.csv chargé avec succès.\n",
      "chunk_24_filtered_part_0.csv chargé avec succès.\n",
      "chunk_27_filtered_part_0.csv chargé avec succès.\n",
      "chunk_26_filtered_part_0.csv chargé avec succès.\n",
      "chunk_20_filtered_part_0.csv chargé avec succès.\n",
      "chunk_21_filtered_part_0.csv chargé avec succès.\n",
      "chunk_22_filtered_part_0.csv chargé avec succès.\n",
      "chunk_23_filtered_part_0.csv chargé avec succès.\n",
      "chunk_11_filtered_part_0.csv chargé avec succès.\n",
      "chunk_16_filtered_part_0.csv chargé avec succès.\n",
      "chunk_17_filtered_part_0.csv chargé avec succès.\n",
      "chunk_14_filtered_part_0.csv chargé avec succès.\n",
      "chunk_15_filtered_part_0.csv chargé avec succès.\n",
      "chunk_19_filtered_part_0.csv chargé avec succès.\n"
     ]
    }
   ],
   "source": [
    "# Initialiser une liste pour stocker les DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Charger chaque fichier CSV et l'ajouter à la liste des DataFrames\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dataframes.append(df)\n",
    "    print(f\"{file} chargé avec succès.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explication :**  \n",
    "- Nous chargeons chaque fichier CSV dans un DataFrame, puis l'ajoutons à la liste `dataframes`.\n",
    "- Cela permet de préparer chaque fichier pour la concaténation.\n",
    "\n",
    "---\n",
    "\n",
    "## Étape 4 : Concaténer tous les DataFrames en un seul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des données consolidées :\n",
      "            code                                                url  \\\n",
      "0  9050482371038  http://world-en.openfoodfacts.org/product/9050...   \n",
      "1  9050482388685  http://world-en.openfoodfacts.org/product/9050...   \n",
      "2  9050482407287  http://world-en.openfoodfacts.org/product/9050...   \n",
      "3  9050482450139  http://world-en.openfoodfacts.org/product/9050...   \n",
      "4  9050482487661  http://world-en.openfoodfacts.org/product/9050...   \n",
      "\n",
      "                      creator     created_t      created_datetime  \\\n",
      "0                     kiliweb  1.663653e+09  2022-09-20T05:58:08Z   \n",
      "1  openfoodfacts-contributors  1.643376e+09  2022-01-28T13:23:57Z   \n",
      "2                     kiliweb  1.652297e+09  2022-05-11T19:29:38Z   \n",
      "3                   dieta2022  1.642262e+09  2022-01-15T15:58:05Z   \n",
      "4                     kiliweb  1.663241e+09  2022-09-15T11:18:02Z   \n",
      "\n",
      "   last_modified_t last_modified_datetime last_modified_by  last_updated_t  \\\n",
      "0     1.722137e+09   2024-07-28T03:26:29Z       quentinbrd    1.724328e+09   \n",
      "1     1.664807e+09   2022-10-03T14:24:40Z       roboto-app    1.707853e+09   \n",
      "2     1.675498e+09   2023-02-04T08:12:42Z      itsjustruby    1.707861e+09   \n",
      "3     1.644517e+09   2022-02-10T18:22:06Z          packbot    1.707852e+09   \n",
      "4     1.682903e+09   2023-05-01T01:10:36Z   guezguez-majed    1.707868e+09   \n",
      "\n",
      "  last_updated_datetime  ... sugars_100g proteins_100g salt_100g sodium_100g  \\\n",
      "0  2024-08-22T11:55:54Z  ...         5.0           7.4      1.17       0.468   \n",
      "1  2024-02-13T19:42:41Z  ...         3.2           NaN      0.68       0.272   \n",
      "2  2024-02-13T21:47:23Z  ...         6.4           4.9      0.20       0.080   \n",
      "3  2024-02-13T19:22:54Z  ...         0.8          16.0      2.50       1.000   \n",
      "4  2024-02-13T23:54:04Z  ...         3.7          13.6      0.08       0.032   \n",
      "\n",
      "   quantity ecoscore_score nutrition-score-fr_100g unique_scans_n  \\\n",
      "0       NaN            NaN                     NaN            NaN   \n",
      "1       NaN            NaN                     NaN            NaN   \n",
      "2       NaN            NaN                     NaN            NaN   \n",
      "3       NaN            NaN                     NaN            NaN   \n",
      "4       NaN            NaN                     NaN            NaN   \n",
      "\n",
      "  image_ingredients_url image_ingredients_small_url  \n",
      "0                   NaN                         NaN  \n",
      "1                   NaN                         NaN  \n",
      "2                   NaN                         NaN  \n",
      "3                   NaN                         NaN  \n",
      "4                   NaN                         NaN  \n",
      "\n",
      "[5 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "# Concaténer tous les DataFrames en un seul\n",
    "data_consolidated = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Afficher un aperçu des premières lignes du fichier consolidé\n",
    "print(\"Aperçu des données consolidées :\")\n",
    "print(data_consolidated.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explication :**  \n",
    "- `pd.concat(dataframes, ignore_index=True)` combine tous les DataFrames de la liste `dataframes` en un seul DataFrame `data_consolidated`.\n",
    "\n",
    "---\n",
    "\n",
    "## Étape 5 : Créer le dossier de sortie et sauvegarder le fichier consolidé\n",
    "\n",
    "Avant de sauvegarder, nous vérifions si le dossier de destination `02_data_consolidation` existe ; s'il n'existe pas, nous le créons avec `os.makedirs()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier consolidé sauvegardé sous : note-books/phase_2_training/02_data_consolidation/data_consolidated.csv\n"
     ]
    }
   ],
   "source": [
    "# Définir le dossier de sortie\n",
    "output_folder = 'note-books/phase_2_training/02_data_consolidation'\n",
    "\n",
    "# Créer le dossier s'il n'existe pas\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Définir le chemin complet pour le fichier consolidé\n",
    "output_path = os.path.join(output_folder, 'data_consolidated.csv')\n",
    "\n",
    "# Sauvegarder le fichier consolidé\n",
    "data_consolidated.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Fichier consolidé sauvegardé sous : {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explication :**  \n",
    "- `os.makedirs(output_folder, exist_ok=True)` crée le dossier `02_data_consolidation` s'il n'existe pas déjà.\n",
    "- `data_consolidated.to_csv(output_path, index=False)` enregistre le DataFrame consolidé dans le dossier `02_data_consolidation` avec le nom `data_consolidated.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "### Résumé\n",
    "\n",
    "Ce notebook :\n",
    "1. Importe les bibliothèques nécessaires.\n",
    "2. Liste les fichiers CSV dans le dossier source.\n",
    "3. Charge chaque fichier CSV et les concatène en un seul DataFrame.\n",
    "4. Crée un dossier `02_data_consolidation` pour ranger le fichier de sortie.\n",
    "5. Sauvegarde le DataFrame consolidé dans `02_data_consolidation/data_consolidated.csv`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
