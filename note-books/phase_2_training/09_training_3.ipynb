{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Mise en place d'une **validation croisée imbriquée** avec un jeu de test final\n",
    "\n",
    "1. **Division initiale des données** : Diviser les données en deux parties :\n",
    "   - **80% des données pour l'entraînement et la validation croisée imbriquée**.\n",
    "   - **20% des données pour un test final** que le modèle ne verra qu'à la toute fin.\n",
    "\n",
    "2. **Validation croisée imbriquée sur les 80% d’entraînement** : Utiliser une validation croisée interne pour optimiser les hyperparamètres du modèle. Cela permet de tester plusieurs combinaisons de paramètres tout en évitant d'exposer le modèle aux données de test final.\n",
    "\n",
    "3. **Évaluation finale** : Une fois le modèle optimisé sur les 80% des données avec validation croisée, l’évaluer sur les 20% restants pour obtenir un score de performance réaliste et indépendant.\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "# Notebook : Optimisation Avancée avec Validation Croisée Imbriquée et Test Final pour Random Forest\n",
    "\n",
    "**Objectifs :**\n",
    "1. Diviser les données en ensembles d’entraînement et de test.\n",
    "2. Effectuer une **validation croisée imbriquée** sur l’ensemble d’entraînement (80%) pour optimiser les hyperparamètres.\n",
    "3. Évaluer la performance finale du modèle optimisé sur le **jeu de test final** (20%).\n",
    "\n",
    "---\n",
    "\n",
    "## Étape 1 : Importer les bibliothèques nécessaires et charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Étape 2 : Diviser les données en ensembles d’entraînement et de test\n",
    "\n",
    "Nous réservons 20% des données pour un test final, tandis que les 80% restants serviront pour l’entraînement et la validation croisée imbriquée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données complètes\n",
    "file_path = 'note-books/phase_2_training/04_correlation_analysis/data_final_features.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Encoder `nutriscore_grade` en valeurs numériques\n",
    "df['nutriscore_grade_encoded'] = df['nutriscore_grade'].map({'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4})\n",
    "\n",
    "# Préparer les variables explicatives et la cible\n",
    "X = df[['fat_100g', 'saturated-fat_100g', 'energy_100g', 'energy-kcal_100g', 'sugars_100g']]\n",
    "y = df['nutriscore_grade_encoded']\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test (80% pour entraînement, 20% pour test final)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Étape 3 : Définir la pipeline et les hyperparamètres pour RandomizedSearchCV sur l’ensemble d’entraînement\n",
    "\n",
    "Nous allons configurer une pipeline et une grille de recherche pour optimiser les hyperparamètres du modèle sur l’ensemble d’entraînement (80%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=100; total time=  20.8s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=100; total time=  20.7s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=100; total time=  20.9s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=100; total time=  20.9s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=100; total time=  20.9s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=150; total time=  36.5s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=150; total time=  36.6s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=150; total time=  36.7s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=150; total time=  36.7s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=150; total time=  36.8s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=50; total time=  11.9s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=50; total time=  12.1s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=50; total time=  12.2s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=50; total time=  12.1s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=50; total time=  12.1s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=150; total time=  37.8s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=150; total time=  37.9s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=150; total time=  38.0s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=150; total time=  38.2s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=150; total time=  38.4s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=1, model__min_samples_split=5, model__n_estimators=100; total time=  21.2s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=1, model__min_samples_split=5, model__n_estimators=100; total time=  21.4s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=1, model__min_samples_split=5, model__n_estimators=100; total time=  21.6s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=1, model__min_samples_split=5, model__n_estimators=100; total time=  21.6s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=1, model__min_samples_split=5, model__n_estimators=100; total time=  21.5s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=50; total time=  10.9s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=50; total time=  10.9s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=50; total time=  10.9s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=50; total time=  11.1s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=2, model__min_samples_split=5, model__n_estimators=50; total time=  11.1s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=100; total time=  25.6s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=100; total time=  25.8s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=100; total time=  25.7s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=100; total time=  25.6s\n",
      "[CV] END model__max_depth=20, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=100; total time=  25.9s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=50; total time=  11.2s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=50; total time=  11.2s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=50; total time=  11.1s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=50; total time=  11.2s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=1, model__min_samples_split=2, model__n_estimators=50; total time=  11.4s\n",
      "[CV] END model__max_depth=10, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=150; total time=  23.5s\n",
      "[CV] END model__max_depth=10, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=150; total time=  23.6s\n",
      "[CV] END model__max_depth=10, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=150; total time=  23.6s\n",
      "[CV] END model__max_depth=10, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=150; total time=  23.7s\n",
      "[CV] END model__max_depth=10, model__min_samples_leaf=2, model__min_samples_split=2, model__n_estimators=150; total time=  23.6s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=1, model__min_samples_split=5, model__n_estimators=150; total time=  29.8s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=1, model__min_samples_split=5, model__n_estimators=150; total time=  29.8s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=1, model__min_samples_split=5, model__n_estimators=150; total time=  30.0s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=1, model__min_samples_split=5, model__n_estimators=150; total time=  29.7s\n",
      "[CV] END model__max_depth=15, model__min_samples_leaf=1, model__min_samples_split=5, model__n_estimators=150; total time=  30.2s\n",
      "Meilleurs paramètres trouvés avec Random Search : {'model__n_estimators': 150, 'model__min_samples_split': 5, 'model__min_samples_leaf': 2, 'model__max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "# Créer une pipeline avec une étape de standardisation et le modèle Random Forest\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Définir une grille de recherche avec des valeurs d'hyperparamètres restreintes\n",
    "param_dist = {\n",
    "    'model__n_estimators': [50, 100, 150],\n",
    "    'model__max_depth': [10, 15, 20],\n",
    "    'model__min_samples_split': [2, 5],\n",
    "    'model__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Configurer RandomizedSearchCV pour la validation croisée imbriquée\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,  # Validation croisée à 5 plis sur l’ensemble d’entraînement\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Entraîner le modèle avec Randomized Search sur l'ensemble d'entraînement (80%)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Extraire les meilleurs paramètres\n",
    "best_params = random_search.best_params_\n",
    "print(\"Meilleurs paramètres trouvés avec Random Search :\", best_params)\n",
    "\n",
    "# Sauvegarder les meilleurs paramètres pour un suivi ultérieur\n",
    "output_folder = 'note-books/phase_2_training/10_random_forest_with_final_test'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "best_params_path = f'{output_folder}/best_hyperparameters.json'\n",
    "with open(best_params_path, 'w') as f:\n",
    "    json.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Étape 4 : Évaluation finale sur le jeu de test\n",
    "\n",
    "Nous utilisons maintenant l'ensemble de test (20%) pour une évaluation finale du modèle optimisé, ce qui donnera une estimation réaliste de ses performances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation finale sur le jeu de test :\n",
      "Mean Squared Error (MSE) : 0.5514624002011859\n",
      "Coefficient de détermination (R²) : 0.6948232057588746\n",
      "Le modèle n'atteint toujours pas le seuil de performance souhaité.\n"
     ]
    }
   ],
   "source": [
    "# Utiliser le meilleur modèle trouvé par Random Search\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Prédire sur le jeu de test final\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculer les métriques de performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Évaluation finale sur le jeu de test :\")\n",
    "print(f\"Mean Squared Error (MSE) : {mse}\")\n",
    "print(f\"Coefficient de détermination (R²) : {r2}\")\n",
    "\n",
    "# Vérification de la performance du modèle\n",
    "target_r2 = 0.85  # Objectif réaliste pour le R²\n",
    "\n",
    "if r2 >= target_r2:\n",
    "    print(f\"Le modèle atteint le seuil de performance souhaité sur le jeu de test final (R² ≥ {target_r2}).\")\n",
    "else:\n",
    "    print(\"Le modèle n'atteint toujours pas le seuil de performance souhaité.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Étape 5 : Sauvegarder le modèle optimisé et ses paramètres\n",
    "\n",
    "Si les performances sont satisfaisantes, nous sauvegardons le modèle optimisé pour les étapes finales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle Random Forest optimisé sauvegardé sous : note-books/phase_2_training/10_random_forest_with_final_test/Random_Forest_final_optimized.joblib\n"
     ]
    }
   ],
   "source": [
    "# Chemin de sauvegarde pour le modèle optimisé\n",
    "model_path_optimized = f'{output_folder}/Random_Forest_final_optimized.joblib'\n",
    "\n",
    "# Sauvegarder le modèle optimisé\n",
    "joblib.dump(best_model, model_path_optimized)\n",
    "print(f\"Modèle Random Forest optimisé sauvegardé sous : {model_path_optimized}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Explication des étapes\n",
    "\n",
    "1. **Division des données** : En gardant 20% pour un test final, on réserve une portion de données non vue pour évaluer la généralisation réelle du modèle.\n",
    "2. **Validation croisée imbriquée** : La validation croisée sur l’ensemble d’entraînement (80%) optimise les hyperparamètres sans utiliser le jeu de test final.\n",
    "3. **Évaluation finale sur le jeu de test** : Cette étape fournit une estimation de la performance du modèle sur des données indépendantes.\n",
    "\n",
    "---\n",
    "\n",
    "### Résumé\n",
    "\n",
    "Dans ce notebook, nous avons :\n",
    "1. Divisé les données en **ensembles d’entraînement (80%) et de test (20%)** pour assurer une évaluation finale indépendante.\n",
    "2. Utilisé **RandomizedSearchCV** pour optimiser les hyperparamètres avec une validation croisée imbriquée sur l’ensemble d’entraînement.\n",
    "3. Évalué le modèle optimisé sur le jeu de test final pour obtenir une estimation réaliste de ses performances.\n",
    "4. Sauvegardé le modèle si les performances répondent aux critères souhaités (par exemple, R² ≥ 0.85).\n",
    "\n",
    "Cela permet une optimisation des hyperparamètres avec une estimation finale fiable sans compromettre la séparation entre entraînement et test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
