{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **Notebook : Analyse et Nettoyage de Données Open Food Facts avec Chunks**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# **Phase 1**\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Importation des bibliothèques**\n",
    "\n",
    "La première section est dédiée à l'importation des bibliothèques nécessaires pour manipuler les fichiers et les données.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importation des bibliothèques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliothèques nécessaires :\n",
    "# - os : pour gérer les fichiers et répertoires.\n",
    "# - pandas : pour lire et manipuler les données CSV.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Définir le chemin du fichier CSV et la taille des chunks**\n",
    "\n",
    "Dans cette étape, nous définissons le chemin vers le fichier CSV et la taille des chunks que nous voulons créer.\n",
    "\n",
    "# 2. Définir le chemin du fichier CSV et la taille des chunks\n",
    "\n",
    "# Chemin du fichier CSV à découper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mwrevent/Dropbox/Mon Mac (Romualdraphique)/Desktop/code/Simplon/brief/Projet-OpenFood/documents_other\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "print(path)\n",
    "#os.chdir('note-books/phase_1_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'note-books/phase_1_data/en.openfoodfacts.org.products.csv'  # Assurez-vous que ce fichier est bien dans votre répertoire\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taille des chunks (100 000 lignes par chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chemin du dossier de sortie où les chunks seront stockés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = 'note-books/phase_1_data/02_chunk-CSV'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Lecture du CSV et division en chunks**\n",
    "\n",
    "Ici, nous implémentons la fonction qui va lire le fichier CSV et le diviser en plusieurs morceaux de 100 000 lignes, puis sauvegarder chaque chunk dans le dossier `02_chunk-CSV`.\n",
    "\n",
    "\n",
    "# Fonction pour lire et diviser le fichier CSV en chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diviser_fichier_en_chunks(file_path, chunk_size, output_directory):\n",
    "    # Lire le fichier CSV en morceaux (chunks)\n",
    "    chunk_iter = pd.read_csv(file_path, sep='\\t', chunksize=chunk_size, low_memory=False, on_bad_lines= \"skip\")\n",
    "    \n",
    "    for i, chunk in enumerate(chunk_iter):\n",
    "        # Sauvegarder chaque chunk dans un fichier CSV distinct\n",
    "        chunk_file_name = os.path.join(output_directory, f'chunk_{i+1}.csv')\n",
    "        chunk.to_csv(chunk_file_name, index=False)\n",
    "        print(f'Chunk {i+1} sauvegardé dans {chunk_file_name}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **`on_bad_lines=\"skip\"`** : Cette option permet d'ignorer automatiquement les lignes corrompues ou mal formatées lors de la lecture des fichiers CSV.\n",
    "\n",
    "# Exécuter le découpage en chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_1.csv.\n",
      "Chunk 2 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_2.csv.\n",
      "Chunk 3 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_3.csv.\n",
      "Chunk 4 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_4.csv.\n",
      "Chunk 5 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_5.csv.\n",
      "Chunk 6 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_6.csv.\n",
      "Chunk 7 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_7.csv.\n",
      "Chunk 8 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_8.csv.\n",
      "Chunk 9 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_9.csv.\n",
      "Chunk 10 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_10.csv.\n",
      "Chunk 11 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_11.csv.\n",
      "Chunk 12 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_12.csv.\n",
      "Chunk 13 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_13.csv.\n",
      "Chunk 14 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_14.csv.\n",
      "Chunk 15 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_15.csv.\n",
      "Chunk 16 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_16.csv.\n",
      "Chunk 17 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_17.csv.\n",
      "Chunk 18 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_18.csv.\n",
      "Chunk 19 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_19.csv.\n",
      "Chunk 20 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_20.csv.\n",
      "Chunk 21 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_21.csv.\n",
      "Chunk 22 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_22.csv.\n",
      "Chunk 23 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_23.csv.\n",
      "Chunk 24 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_24.csv.\n",
      "Chunk 25 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_25.csv.\n",
      "Chunk 26 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_26.csv.\n",
      "Chunk 27 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_27.csv.\n",
      "Chunk 28 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_28.csv.\n",
      "Chunk 29 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_29.csv.\n",
      "Chunk 30 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_30.csv.\n",
      "Chunk 31 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_31.csv.\n",
      "Chunk 32 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_32.csv.\n",
      "Chunk 33 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_33.csv.\n",
      "Chunk 34 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_34.csv.\n",
      "Chunk 35 sauvegardé dans note-books/phase_1_data/02_chunk-CSV/chunk_35.csv.\n"
     ]
    }
   ],
   "source": [
    "diviser_fichier_en_chunks(csv_file_path, chunk_size, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Conclusion**\n",
    "\n",
    "À ce stade, votre fichier CSV sera divisé en chunks de 100 000 lignes, et chaque chunk sera sauvegardé dans le dossier `02_chunk-CSV`. Vous pouvez vérifier le dossier pour voir les fichiers générés.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Résumé des étapes\n",
    "\n",
    "1. **Importation des bibliothèques** : Importer `os` et `pandas` pour gérer les fichiers et manipuler les données.\n",
    "2. **Définir le chemin du fichier CSV et la taille des chunks** : Spécifier le fichier CSV à diviser et la taille des chunks (100 000 lignes).\n",
    "3. **Lecture et division en chunks** : Diviser le fichier CSV en chunks et sauvegarder chaque chunk dans le dossier `02_chunk-CSV`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
