{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# **Notebook 10 : Traduction et Normalisation des Noms de Pays en Français avec ISO 3166**\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Importation des Bibliothèques**\n",
    "\n",
    "Dans cette section, nous importons les bibliothèques nécessaires pour la lecture des fichiers, la manipulation des données, et la traduction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques\n",
    "import os\n",
    "import pandas as pd\n",
    "from googletrans import Translator  # Assurez-vous d'avoir installé googletrans==4.0.0-rc1\n",
    "import time\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **2. Chargement de la Base ISO 3166 et Préparation des Données**\n",
    "\n",
    "Nous allons charger la base ISO 3166 depuis `all.csv` et créer un dictionnaire de correspondance pour convertir les codes de pays en noms français normalisés.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple de mapping ISO: [('af', 'Afghanistan'), ('afg', 'Afghanistan'), ('afghanistan', 'Afghanistan'), ('ax', 'Åland islands'), ('ala', 'Åland islands')]\n"
     ]
    }
   ],
   "source": [
    "# Chemin du fichier ISO\n",
    "iso_path = 'note-books/phase_1_data/all.csv'\n",
    "df_iso = pd.read_csv(iso_path)\n",
    "\n",
    "# Création du dictionnaire de correspondance : code ISO (alpha-2 et alpha-3) et nom du pays en français\n",
    "iso_mapping = {}\n",
    "\n",
    "# Utilisation des codes alpha-2 et alpha-3 avec le nom du pays\n",
    "for _, row in df_iso.iterrows():\n",
    "    name = row['name']\n",
    "    alpha_2 = row['alpha-2']\n",
    "    alpha_3 = row['alpha-3']\n",
    "    \n",
    "    if isinstance(name, str):\n",
    "        name = name.strip().capitalize()\n",
    "        if isinstance(alpha_2, str):\n",
    "            iso_mapping[alpha_2.strip().lower()] = name\n",
    "        if isinstance(alpha_3, str):\n",
    "            iso_mapping[alpha_3.strip().lower()] = name\n",
    "        iso_mapping[name.lower()] = name  # Ajout du nom lui-même en minuscule pour la correspondance directe\n",
    "\n",
    "# Vérification des premières correspondances pour confirmation\n",
    "print(\"Exemple de mapping ISO:\", list(iso_mapping.items())[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **3. Définition de la Fonction de Traduction et de Normalisation**\n",
    "\n",
    "La fonction ci-dessous lit les chunks de fichiers, normalise les noms de pays, effectue les traductions, et les applique sur chaque chunk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traduire_pays_en_francais(input_directory, output_directory, batch_size=50, encoding='ISO-8859-1'):\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    translator = Translator()\n",
    "    pays_uniques = set()\n",
    "\n",
    "    # Étape 1 : Collection des noms de pays uniques\n",
    "    print(\"Étape 1 : Collection des noms de pays uniques\")\n",
    "    for file_name in os.listdir(input_directory):\n",
    "        input_file_path = os.path.join(input_directory, file_name)\n",
    "        \n",
    "        # Gestion des erreurs d'encodage\n",
    "        try:\n",
    "            chunk_iter = pd.read_csv(input_file_path, sep=',', chunksize=10000, low_memory=False, on_bad_lines=\"skip\", encoding=encoding)\n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"Problème d'encodage pour {file_name}. Réessai avec 'utf-8'.\")\n",
    "            chunk_iter = pd.read_csv(input_file_path, sep=',', chunksize=10000, low_memory=False, on_bad_lines=\"skip\", encoding='utf-8')\n",
    "        \n",
    "        for chunk in chunk_iter:\n",
    "            if 'countries' in chunk.columns:\n",
    "                chunk['countries_cleaned'] = chunk['countries'].apply(\n",
    "                    lambda x: [p.strip().removeprefix(\"en:\") for p in str(x).split(',') if p.strip()] if pd.notna(x) else []\n",
    "                )\n",
    "                pays_uniques.update([p for sublist in chunk['countries_cleaned'] for p in sublist if re.match(r'^[a-zA-Z\\s]+$', p)])\n",
    "\n",
    "    # Étape 2 : Traduction des pays uniques en français\n",
    "    print(f\"Étape 2 : Traduction des {len(pays_uniques)} pays uniques\")\n",
    "    traduction_pays = {}\n",
    "    pays_list = [p for p in pays_uniques if p]\n",
    "\n",
    "    for i, country in enumerate(pays_list, start=1):\n",
    "        try:\n",
    "            # Nettoyage des préfixes \"en:\" avant la traduction\n",
    "            clean_country = country.removeprefix(\"en:\").strip()\n",
    "            traduction = translator.translate(clean_country, src='auto', dest='fr').text\n",
    "            traduction_pays[country] = traduction\n",
    "            time.sleep(0.5)\n",
    "            if i % batch_size == 0:\n",
    "                print(f\"{i} pays traduits sur {len(pays_list)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur de traduction pour {country}: {e}\")\n",
    "            traduction_pays[country] = \"unknown\"\n",
    "\n",
    "    # Étape 3 : Remplacement des noms de pays et sauvegarde des fichiers traduits\n",
    "    print(\"Étape 3 : Remplacement des noms de pays et sauvegarde des fichiers traduits\")\n",
    "    for file_name in os.listdir(input_directory):\n",
    "        input_file_path = os.path.join(input_directory, file_name)\n",
    "        output_file_path = os.path.join(output_directory, file_name)\n",
    "\n",
    "        try:\n",
    "            chunk_iter = pd.read_csv(input_file_path, sep=',', chunksize=10000, low_memory=False, on_bad_lines=\"skip\", encoding=encoding)\n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"Problème d'encodage pour {file_name}. Réessai avec 'utf-8'.\")\n",
    "            chunk_iter = pd.read_csv(input_file_path, sep=',', chunksize=10000, low_memory=False, on_bad_lines=\"skip\", encoding='utf-8')\n",
    "        \n",
    "        for i, chunk in enumerate(chunk_iter):\n",
    "            if 'countries' in chunk.columns:\n",
    "                chunk['countries_cleaned'] = chunk['countries'].apply(\n",
    "                    lambda x: [p.strip().removeprefix(\"en:\") for p in str(x).split(',') if p.strip()] if pd.notna(x) else []\n",
    "                )\n",
    "                chunk['countries_translated'] = chunk['countries_cleaned'].apply(\n",
    "                    lambda countries: ', '.join([traduction_pays.get(country, \"unknown\") for country in countries])\n",
    "                )\n",
    "                \n",
    "                if i == 0:\n",
    "                    chunk.to_csv(output_file_path, mode='w', index=False)\n",
    "                else:\n",
    "                    chunk.to_csv(output_file_path, mode='a', index=False, header=False)\n",
    "        \n",
    "        print(f\"Fichier traduit et sauvegardé : {output_file_path}\")\n",
    "\n",
    "    print(\"Processus de traduction terminé.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Répertoires d'Entrée et de Sortie**\n",
    "\n",
    "Configurez les répertoires pour les chunks traduits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Répertoires d'entrée et de sortie\n",
    "input_directory = 'note-books/phase_1_data/08_data_countries'\n",
    "output_directory = 'note-books/phase_1_data/09_translated_countries'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **5. Exécution de la Fonction de Traduction et Normalisation**\n",
    "\n",
    "Exécutez la fonction `traduire_pays_en_francais` pour appliquer les traductions et normalisations sur les fichiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Étape 1 : Collection des noms de pays uniques\n",
      "Étape 2 : Traduction des 749 pays uniques\n",
      "50 pays traduits sur 749\n",
      "Erreur de traduction pour Filipinas: 'NoneType' object is not iterable\n",
      "100 pays traduits sur 749\n",
      "150 pays traduits sur 749\n",
      "200 pays traduits sur 749\n",
      "250 pays traduits sur 749\n",
      "300 pays traduits sur 749\n",
      "350 pays traduits sur 749\n",
      "Erreur de traduction pour gr: 'NoneType' object is not iterable\n",
      "400 pays traduits sur 749\n",
      "Erreur de traduction pour my: 'NoneType' object is not iterable\n",
      "450 pays traduits sur 749\n",
      "500 pays traduits sur 749\n",
      "Erreur de traduction pour International: 'NoneType' object is not iterable\n",
      "550 pays traduits sur 749\n",
      "600 pays traduits sur 749\n",
      "650 pays traduits sur 749\n",
      "Erreur de traduction pour ar: 'NoneType' object is not iterable\n",
      "700 pays traduits sur 749\n",
      "Erreur de traduction pour vu: 'NoneType' object is not iterable\n",
      "Erreur de traduction pour GR: 'NoneType' object is not iterable\n",
      "Étape 3 : Remplacement des noms de pays et sauvegarde des fichiers traduits\n",
      "Fichier traduit et sauvegardé : note-books/phase_1_data/09_translated_countries/chunk_35_filtered_part_0.csv\n",
      "Fichier traduit et sauvegardé : note-books/phase_1_data/09_translated_countries/chunk_34_filtered_part_0.csv\n",
      "Fichier traduit et sauvegardé : note-books/phase_1_data/09_translated_countries/.DS_Store\n",
      "Fichier traduit et sauvegardé : note-books/phase_1_data/09_translated_countries/chunk_33_filtered_part_0.csv\n",
      "Fichier traduit et sauvegardé : note-books/phase_1_data/09_translated_countries/chunk_29_filtered_part_0.csv\n",
      "Fichier traduit et sauvegardé : note-books/phase_1_data/09_translated_countries/chunk_30_filtered_part_0.csv\n",
      "Fichier traduit et sauvegardé : note-books/phase_1_data/09_translated_countries/chunk_28_filtered_part_0.csv\n",
      "Fichier traduit et sauvegardé : note-books/phase_1_data/09_translated_countries/chunk_31_filtered_part_0.csv\n",
      "Fichier traduit et sauvegardé : note-books/phase_1_data/09_translated_countries/chunk_25_filtered_part_0.csv\n",
      "Fichier traduit et sauvegardé : note-books/phase_1_data/09_translated_countries/chunk_24_filtered_part_0.csv\n",
      "Fichier traduit et sauvegardé : note-books/phase_1_data/09_translated_countries/chunk_27_filtered_part_0.csv\n",
      "Fichier traduit et sauvegardé : note-books/phase_1_data/09_translated_countries/chunk_26_filtered_part_0.csv\n",
      "Fichier traduit et sauvegardé : note-books/phase_1_data/09_translated_countries/chunk_20_filtered_part_0.csv\n",
      "Fichier traduit et sauvegardé : note-books/phase_1_data/09_translated_countries/chunk_21_filtered_part_0.csv\n",
      "Fichier traduit et sauvegardé : note-books/phase_1_data/09_translated_countries/chunk_22_filtered_part_0.csv\n",
      "Fichier traduit et sauvegardé : note-books/phase_1_data/09_translated_countries/chunk_23_filtered_part_0.csv\n",
      "Fichier traduit et sauvegardé : note-books/phase_1_data/09_translated_countries/chunk_11_filtered_part_0.csv\n",
      "Fichier traduit et sauvegardé : note-books/phase_1_data/09_translated_countries/chunk_16_filtered_part_0.csv\n",
      "Fichier traduit et sauvegardé : note-books/phase_1_data/09_translated_countries/chunk_17_filtered_part_0.csv\n",
      "Fichier traduit et sauvegardé : note-books/phase_1_data/09_translated_countries/chunk_14_filtered_part_0.csv\n",
      "Fichier traduit et sauvegardé : note-books/phase_1_data/09_translated_countries/chunk_15_filtered_part_0.csv\n",
      "Fichier traduit et sauvegardé : note-books/phase_1_data/09_translated_countries/chunk_19_filtered_part_0.csv\n",
      "Processus de traduction terminé.\n"
     ]
    }
   ],
   "source": [
    "traduire_pays_en_francais(input_directory, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Explications**\n",
    "\n",
    "- **Normalisation ISO 3166** : Les noms de pays et codes ISO sont comparés à la base pour garantir des noms français standardisés.\n",
    "- **Gestion des préfixes \"en:\"** : Tout préfixe \"en:\" est automatiquement supprimé.\n",
    "- **Création de lignes séparées** : Chaque pays dans une même cellule est converti en une ligne distincte pour simplifier les analyses.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
